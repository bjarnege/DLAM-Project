{"cells":[{"cell_type":"code","source":["!pip install medmnist"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTSAJOzAOi2l","executionInfo":{"status":"ok","timestamp":1684747401565,"user_tz":-120,"elapsed":4289,"user":{"displayName":"Ruben Harle","userId":"08246226745262316953"}},"outputId":"3bf9d1ca-df8f-49d4-de7f-9f04438ea0f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: medmnist in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n","Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.5.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.2+cu118)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.4.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvV1g1-VKC1e"},"outputs":[],"source":["import os\n","import numpy as np\n","import math\n","\n","import torchvision.transforms as transforms\n","from torchvision.utils import save_image\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets\n","from torch.autograd import Variable\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7wUP0cbKFzF"},"outputs":[],"source":["os.makedirs(\"images\", exist_ok=True)\n","\n","n_epochs = 200\n","batch_size = 256\n","lr = 0.001\n","b1 = 0.5\n","b2 = 0.999\n","n_cpu = -1\n","latent_dim = 100\n","n_classes = 8\n","img_size = 28\n","channels = 1\n","sample_interval = 400\n","\n","cuda = True if torch.cuda.is_available() else False\n"]},{"cell_type":"code","source":["import os\n","import torch\n","from torchvision import datasets, transforms\n","from medmnist import dataset\n","from medmnist import INFO"],"metadata":{"id":"SmRyRmqpOPIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2897,"status":"ok","timestamp":1684747408431,"user":{"displayName":"Ruben Harle","userId":"08246226745262316953"},"user_tz":-120},"id":"WBGnhCUuJ_WG","outputId":"ec815f21-5932-4842-c533-a2d2b9cef5a8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: /root/.medmnist/tissuemnist.npz\n","Using downloaded and verified file: /root/.medmnist/tissuemnist.npz\n"]}],"source":["torch.manual_seed(1312)\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find(\"BatchNorm2d\") != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","\n","        self.label_emb = nn.Embedding(n_classes, latent_dim)\n","\n","        self.init_size = img_size // 4  # Initial size before upsampling\n","        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n","\n","        self.conv_blocks = nn.Sequential(\n","            nn.BatchNorm2d(128),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(128, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Upsample(scale_factor=2),\n","            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, 64, 3, stride=1, padding=1),\n","            nn.BatchNorm2d(64, 0.8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n","            nn.Tanh(),\n","        )\n","\n","    def forward(self, noise, labels):\n","        gen_input = torch.mul(self.label_emb(labels), noise)\n","        out = self.l1(gen_input)\n","        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n","        img = self.conv_blocks(out)\n","        return img\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        def discriminator_block(in_filters, out_filters, bn=True):\n","            \"\"\"Returns layers of each discriminator block\"\"\"\n","            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.4\n","                                                                                                                )]\n","            if bn:\n","                block.append(nn.BatchNorm2d(out_filters, 0.8))\n","            return block\n","\n","        self.conv_blocks = nn.Sequential(\n","            *discriminator_block(channels, 16, bn=False),\n","            *discriminator_block(16, 32),\n","            *discriminator_block(32, 64),\n","            *discriminator_block(64, 128),\n","            *discriminator_block(128, 128),\n","        )\n","\n","        # The height and width of downsampled image\n","        ds_size = img_size // 2 ** 4\n","\n","        # self.tmp = ds_size\n","        # Output layers\n","        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n","        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, n_classes), nn.Softmax())\n","\n","    def forward(self, img):\n","        out = self.conv_blocks(img)\n","        out = out.view(out.shape[0], -1)\n","        # print(self.tmp)\n","        # print(128 * self.tmp ** 2)\n","        # print(out.shape)\n","        validity = self.adv_layer(out)\n","        label = self.aux_layer(out)\n","\n","        return validity, label\n","\n","\n","# Loss functions\n","adversarial_loss = torch.nn.BCELoss()\n","auxiliary_loss = torch.nn.CrossEntropyLoss()\n","\n","# Initialize generator and discriminator\n","generator = Generator()\n","discriminator = Discriminator()\n","\n","if cuda:\n","    generator.cuda()\n","    discriminator.cuda()\n","    adversarial_loss.cuda()\n","    auxiliary_loss.cuda()\n","\n","# Initialize weights\n","generator.apply(weights_init_normal)\n","discriminator.apply(weights_init_normal)\n","\n","# Configure data loader\n","data_dir = \"../../data/medmnist\"  # Path to the MedMNIST dataset directory\n","os.makedirs(data_dir, exist_ok=True)\n","# dataloader = torch.utils.data.DataLoader(datasets.MNIST(\n","#     \"../../data/mnist\",\n","#     train=True,\n","#     download=True,\n","#     transform=transforms.Compose(\n","#         [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n","#     ),\n","# ),\n","#     batch_size=batch_size,\n","#     shuffle=True,\n","# )\n","dataloader = torch.utils.data.DataLoader(\n","    dataset.TissueMNIST(\n","        # root=data_dir,\n","        split='train',\n","        transform=transforms.Compose([\n","            transforms.Resize(img_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5], [0.5])\n","        ]),\n","        target_transform=transforms.Lambda(lambda x: x[0]),\n","        # flag=dataset_name,\n","        download=True\n","    ),\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","dataloader_test = torch.utils.data.DataLoader(\n","    dataset.TissueMNIST(\n","        # root=data_dir,\n","        split='test',\n","        transform=transforms.Compose([\n","            transforms.Resize(img_size),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5], [0.5])\n","        ]),\n","        target_transform=transforms.Lambda(lambda x: x[0]),\n","        # flag=dataset_name,\n","        download=True\n","    ),\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n","optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))\n","\n","scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer_G, step_size=len(dataloader)*5, gamma=0.5, last_epoch=- 1, verbose=False)\n","scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer_D, step_size=len(dataloader)*5, gamma=0.5, last_epoch=- 1, verbose=False)\n","\n","FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n","LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n","\n","\n","def sample_image(n_row, batches_done):\n","    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n","    # Sample noise\n","    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, latent_dim))))\n","    # Get labels ranging from 0 to n_classes for n rows\n","    labels = np.array([num for _ in range(n_row) for num in range(n_row)])\n","    labels = Variable(LongTensor(labels))\n","    gen_imgs = generator(z, labels)\n","    save_image(gen_imgs.data, \"images/%d.png\" % batches_done, nrow=n_row, normalize=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wevVbC_jKlga","outputId":"747f87b2-20ac-47ff-d447-a97c448edb7a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  input = module(input)\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch 0/200] [Batch 0/647] [D loss: 1.371602, acc: 8%] [G loss: 1.371570]\n","[Epoch 0/200] [Batch 50/647] [D loss: 1.149022, acc: 36%] [G loss: 1.168343]\n","[Epoch 0/200] [Batch 100/647] [D loss: 0.985801, acc: 44%] [G loss: 1.079924]\n","[Epoch 0/200] [Batch 150/647] [D loss: 0.963104, acc: 38%] [G loss: 1.019454]\n","[Epoch 0/200] [Batch 200/647] [D loss: 0.948442, acc: 39%] [G loss: 1.016670]\n","[Epoch 0/200] [Batch 250/647] [D loss: 0.911659, acc: 46%] [G loss: 0.990356]\n","[Epoch 0/200] [Batch 300/647] [D loss: 0.908557, acc: 47%] [G loss: 0.952229]\n","[Epoch 0/200] [Batch 350/647] [D loss: 0.922223, acc: 42%] [G loss: 0.953874]\n","[Epoch 0/200] [Batch 400/647] [D loss: 0.917200, acc: 43%] [G loss: 0.969383]\n","[Epoch 0/200] [Batch 450/647] [D loss: 0.908202, acc: 46%] [G loss: 0.937334]\n","[Epoch 0/200] [Batch 500/647] [D loss: 0.906127, acc: 44%] [G loss: 0.915776]\n","[Epoch 0/200] [Batch 550/647] [D loss: 0.926643, acc: 42%] [G loss: 0.898397]\n","[Epoch 0/200] [Batch 600/647] [D loss: 0.886669, acc: 50%] [G loss: 0.888604]\n","TEST acc: 13%\n","TEST real acc: 13%\n","TEST fake acc: 14%\n","LR:  [0.001] [0.001]\n","[Epoch 1/200] [Batch 0/647] [D loss: 0.900266, acc: 46%] [G loss: 0.886539]\n","[Epoch 1/200] [Batch 50/647] [D loss: 0.899743, acc: 46%] [G loss: 0.910274]\n","[Epoch 1/200] [Batch 100/647] [D loss: 0.905933, acc: 46%] [G loss: 0.919355]\n","[Epoch 1/200] [Batch 150/647] [D loss: 0.890074, acc: 48%] [G loss: 0.859866]\n","[Epoch 1/200] [Batch 200/647] [D loss: 0.902579, acc: 46%] [G loss: 0.897468]\n","[Epoch 1/200] [Batch 250/647] [D loss: 0.884300, acc: 49%] [G loss: 0.892501]\n","[Epoch 1/200] [Batch 300/647] [D loss: 0.891076, acc: 50%] [G loss: 0.889690]\n","[Epoch 1/200] [Batch 350/647] [D loss: 0.908857, acc: 46%] [G loss: 0.887672]\n","[Epoch 1/200] [Batch 400/647] [D loss: 0.915899, acc: 43%] [G loss: 0.881506]\n","[Epoch 1/200] [Batch 450/647] [D loss: 0.915563, acc: 41%] [G loss: 0.861849]\n","[Epoch 1/200] [Batch 500/647] [D loss: 0.898817, acc: 46%] [G loss: 0.874491]\n","[Epoch 1/200] [Batch 550/647] [D loss: 0.886339, acc: 50%] [G loss: 0.871514]\n","[Epoch 1/200] [Batch 600/647] [D loss: 0.897978, acc: 48%] [G loss: 0.862479]\n","TEST acc: 14%\n","TEST real acc: 14%\n","TEST fake acc: 14%\n","LR:  [0.001] [0.001]\n","[Epoch 2/200] [Batch 0/647] [D loss: 0.886425, acc: 48%] [G loss: 0.884671]\n","[Epoch 2/200] [Batch 50/647] [D loss: 0.881193, acc: 51%] [G loss: 0.878023]\n","[Epoch 2/200] [Batch 100/647] [D loss: 0.910803, acc: 46%] [G loss: 0.877308]\n","[Epoch 2/200] [Batch 150/647] [D loss: 0.910803, acc: 43%] [G loss: 0.906468]\n","[Epoch 2/200] [Batch 200/647] [D loss: 0.882099, acc: 50%] [G loss: 0.905367]\n","[Epoch 2/200] [Batch 250/647] [D loss: 0.905682, acc: 46%] [G loss: 0.908290]\n","[Epoch 2/200] [Batch 300/647] [D loss: 0.905822, acc: 44%] [G loss: 0.900099]\n","[Epoch 2/200] [Batch 350/647] [D loss: 0.884902, acc: 50%] [G loss: 0.872173]\n","[Epoch 2/200] [Batch 400/647] [D loss: 0.905837, acc: 45%] [G loss: 0.888210]\n","[Epoch 2/200] [Batch 450/647] [D loss: 0.883197, acc: 50%] [G loss: 0.887344]\n","[Epoch 2/200] [Batch 500/647] [D loss: 0.890773, acc: 48%] [G loss: 0.881906]\n","[Epoch 2/200] [Batch 550/647] [D loss: 0.876494, acc: 51%] [G loss: 0.898561]\n","[Epoch 2/200] [Batch 600/647] [D loss: 0.901414, acc: 46%] [G loss: 0.907228]\n"]}],"source":["# ----------\n","#  Training\n","# ----------\n","\n","for epoch in range(n_epochs):\n","    for i, (imgs, labels) in enumerate(dataloader):\n","        generator.train()\n","        discriminator.train()\n","        batch_size = imgs.shape[0]\n","\n","        # Adversarial ground truths\n","        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n","        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n","\n","        # Configure input\n","        real_imgs = Variable(imgs.type(FloatTensor))\n","        labels = Variable(labels.type(LongTensor))\n","\n","        # -----------------\n","        #  Train Generator\n","        # -----------------\n","\n","        optimizer_G.zero_grad()\n","        # scheduler_G.zero_grad()\n","\n","        # Sample noise and labels as generator input\n","        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n","        gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n","\n","        # Generate a batch of images\n","        gen_imgs = generator(z, gen_labels)\n","\n","        # Loss measures generator's ability to fool the discriminator\n","        validity, pred_label = discriminator(gen_imgs)\n","        g_loss = 0.5 * (adversarial_loss(validity, valid) + auxiliary_loss(pred_label, gen_labels))\n","\n","        g_loss.backward()\n","        optimizer_G.step()\n","        scheduler_G.step()\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","\n","        optimizer_D.zero_grad()\n","        # scheduler_D.zero_grad()\n","\n","        # Loss for real images\n","        real_pred, real_aux = discriminator(real_imgs)\n","        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n","\n","        # Loss for fake images\n","        # fake_pred, fake_aux = discriminator(gen_imgs.detach())\n","        # d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, gen_labels)) / 2\n","\n","        # Total discriminator loss\n","        # d_loss = (d_real_loss + d_fake_loss) / 2\n","        d_loss = d_real_loss\n","\n","        if i % 50 == 0:\n","            # Calculate discriminator accuracy\n","            pred = np.concatenate([real_aux.data.cpu().numpy()], axis=0)\n","            # pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n","            gt = np.concatenate([labels.data.cpu().numpy()], axis=0)\n","            # gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n","            d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n","            print(\n","                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n","                % (epoch, n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n","            )\n","\n","        d_loss.backward()\n","        optimizer_D.step()\n","        scheduler_D.step()\n","\n","        batches_done = epoch * len(dataloader) + i\n","        if batches_done % sample_interval == 0:\n","            sample_image(n_row=n_classes, batches_done=batches_done)\n","\n","    avg_acc = 0\n","    avg_real_acc = 0\n","    avg_fake_acc = 0\n","\n","    for i, (imgs, labels) in enumerate(dataloader_test):\n","        generator.eval()\n","        discriminator.eval()\n","        batch_size = imgs.shape[0]\n","\n","        # Adversarial ground truths\n","        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n","        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n","\n","        # Configure input\n","        real_imgs = Variable(imgs.type(FloatTensor))\n","        labels = Variable(labels.type(LongTensor))\n","\n","        # -----------------\n","        #  Test Generator\n","        # -----------------\n","\n","        # Sample noise and labels as generator input\n","        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n","        gen_labels = Variable(LongTensor(np.random.randint(0, n_classes, batch_size)))\n","\n","        # Generate a batch of images\n","        gen_imgs = generator(z, gen_labels)\n","\n","        # Loss measures generator's ability to fool the discriminator\n","        validity, pred_label = discriminator(gen_imgs)\n","\n","\n","        # ---------------------\n","        #  Test Discriminator\n","        # ---------------------\n","\n","        # Loss for real images\n","        real_pred, real_aux = discriminator(real_imgs)\n","\n","        # Loss for fake images\n","        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n","\n","        # Calculate discriminator accuracy\n","        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n","        gt = np.concatenate([labels.data.cpu().numpy(), gen_labels.data.cpu().numpy()], axis=0)\n","        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n","        avg_acc += d_acc\n","\n","        avg_real_acc += np.mean(np.argmax(real_aux.data.cpu().numpy(), axis=1) == labels.data.cpu().numpy())\n","        avg_fake_acc += np.mean(np.argmax(fake_aux.data.cpu().numpy(), axis=1) == gen_labels.data.cpu().numpy())\n","\n","        # print(\n","        #     \"TEST [Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n","        #     % (epoch, n_epochs, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n","        # )\n","        batches_done = epoch * len(dataloader_test) + i\n","        if batches_done % sample_interval == 0:\n","            sample_image(n_row=n_classes, batches_done=batches_done)\n","\n","    print(\"TEST acc: %d%%\" % (100 * avg_acc / len(dataloader)))\n","    print(\"TEST real acc: %d%%\" % (100 * avg_real_acc / len(dataloader)))\n","    print(\"TEST fake acc: %d%%\" % (100 * avg_fake_acc / len(dataloader)))\n","    print(\"LR: \", scheduler_D.get_last_lr(), scheduler_G.get_last_lr())\n"]},{"cell_type":"code","source":[],"metadata":{"id":"ZsbKxBLVgurF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1c9s9xRAiLZ8ulqiGpKGAQWmy4-m-bOmP","timestamp":1687189138411},{"file_id":"1Qv8yW2SndNAQs0qr8wx1FVsrDdwjmZZi","timestamp":1684502994831}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}